# ğŸš€ Ã‰tape 4 : CrÃ©ation d'un pipeline ETL avec Airflow

## ğŸ¯ Objectif

CrÃ©er un pipeline ETL (Extract, Transform, Load) avec Airflow pour :

1. Extraire des donnÃ©es de ventes de magasins en France et aux Ã‰tats-Unis.
2. Transformer les donnÃ©es en convertissant les prix en GBP.
3. Charger les donnÃ©es transformÃ©es dans un fichier CSV.
4. GÃ©nÃ©rer un rapport consolidÃ©.

---

## ğŸ“š Ressources
- [Documentation officielle d'Airflow](https://airflow.apache.org/docs/)
- [PythonOperator](https://airflow.apache.org/docs/apache-airflow/stable/howto/operator/python.html)
- [Pandas Documentation](https://pandas.pydata.org/docs/)

---

## ğŸ“ Ã‰tapes du TD

### Exercice 1 : Mise en place du pipeline de la France

#### Partie 1 : Extraction des donnÃ©es pour la France

??? tip "Astuce"
      - Pensez Ã  bien initialiser le rÃ©pertoire de donnÃ©es avec `os.makedirs()`.
      - Les `default_args` sont essentiels pour la configuration du DAG.
      - Utilisez `datetime.now()` pour la date de dÃ©but.

??? example "Code initial"
    ```python { .py .copy }
    from airflow import DAG
    from airflow.operators.python_operator import PythonOperator
    from datetime import datetime, timedelta
    import random
    import pandas as pd
    import os

    # Configuration
    AIRFLOW_HOME = os.getenv('AIRFLOW_HOME', '/opt/airflow')
    DATA_DIR = os.path.join(AIRFLOW_HOME, 'data')
    CSV_FILE = os.path.join(DATA_DIR, 'vente.csv')
    os.makedirs(DATA_DIR, exist_ok=True)

    # Taux de conversion (simulÃ©)
    TAUX_CONVERSION = {
        'EUR_TO_GBP': 0.85,  # 1 EUR = 0.85 GBP
        'USD_TO_GBP': 0.79   # 1 USD = 0.79 GBP
    }

    # DonnÃ©es des magasins avec prix en devise locale
    magasins = {
        "usa": {
            "pays": "Ã‰tats-Unis",
            "devise": "USD",
            "villes": ["New York", "Los Angeles"],
            "noms_magasin": ["SuperMart USA", "QuickShop USA"],
            "produits": {
                "Pommes": 1.80,  # Prix en USD
                "Bananes": 0.95,
                "Lait": 2.40,
                "Pain": 1.45,
                "Å’ufs": 3.00
            },
            "vendeurs": ["Alice", "Bob", "Charlie", "David", "Eve"]
        },
        "france": {
            "pays": "France",
            "devise": "EUR",
            "villes": ["Paris", "Lyon"],
            "noms_magasin": ["SuperMart France", "QuickShop France"],
            "produits": {
                "Pommes": 1.30,  # Prix en EUR
                "Bananes": 0.70,
                "Lait": 1.80,
                "Pain": 1.00,
                "Å’ufs": 2.20
            },
            "vendeurs": ["Jean", "Marie", "Pierre", "Sophie", "Luc"]
        }
    }

    def extraction_ventes(magasin_key):
        """
        Extrait les donnÃ©es de vente pour un magasin.
        """
        magasin = magasins[magasin_key]
        ventes = []
        
        for produit, prix_unitaire in magasin["produits"].items():
            for vendeur in magasin["vendeurs"]:
                ville = random.choice(magasin["villes"])
                nom_magasin = random.choice(magasin["noms_magasin"])
                quantite_vendue = random.randint(1, 10)
                prix_total = quantite_vendue * prix_unitaire
                
                ventes.append({
                    "pays": magasin["pays"],
                    "devise_origine": magasin["devise"],
                    "ville": ville,
                    "nom_magasin": nom_magasin,
                    "produit": produit,
                    "prix_unitaire_original": prix_unitaire,
                    "vendeur": vendeur,
                    "quantite_vendue": quantite_vendue,
                    "prix_total_original": prix_total,
                    "date_vente": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                })
        
        return ventes

    def extract_france():
        """Extraction des donnÃ©es France"""
        return extraction_ventes("france")

    # Configuration du DAG
    default_args = {
     # Ã€ complÃ©ter
    }

    # CrÃ©ation du DAG
    dag = DAG(
     # Ã€ complÃ©ter
    )
    
    # TÃ¢ches d'extraction
    extract_france_task = PythonOperator(
     # Ã€ complÃ©ter
    )
    ```

1. CrÃ©ez un fichier `etl_ventes_dag.py` dans le dossier `dags` d'Airflow.

2. ComplÃ©tez le dictionnaire `default_args` avec :
   
      - `owner`: votre nom
      - `retries`: 2
      - `retry_delay`: 10 minutes
      - `start_date`: date actuelle

3. ComplÃ©tez le code de l'instance DAG avec :
   
      - ID: `etl_ventes_pipeline`
      - Arguments par dÃ©faut: `default_args=default_args`
      - Description personnalisÃ©e
      - Intervalle d'exÃ©cution : 5 minutes

4. DÃ©finissez la tÃ¢che `extract_france_task` avec :
   
      - `task_id='extract_france'`
      - `python_callable=extract_france`
      - `dag=dag`

5. ğŸ” VÃ©rification :
   
   Lancez le DAG `etl_ventes_pipeline`, double-cliquez sur `extract_france_task` et vÃ©rifiez les donnÃ©es extraites dans l'onglet XCom.

??? success "Solution complÃ¨te"
    ```python { .py .copy }
    # Configuration du DAG
    default_args = {
        'owner': 'votre_nom',
        'depends_on_past': False,
        'start_date': datetime(2025, 2, 25),
        'retries': 2,
        'retry_delay': timedelta(minutes=10),
    }

    # CrÃ©ation du DAG
    dag = DAG(
        'etl_ventes_pipeline',
        default_args=default_args,
        description='Pipeline ETL pour les donnÃ©es de vente',
        schedule_interval=timedelta(minutes=5),
        catchup=False,
    )

    # TÃ¢che d'extraction France
    extract_france_task = PythonOperator(
        task_id='extract_france',
        python_callable=extract_france,
        dag=dag,
    )
    ```

---

#### Partie 2 : Transformation des donnÃ©es pour la France

??? tip "Astuce"
       - Utilisez la fonction `xcom_pull()` pour rÃ©cupÃ©rer les donnÃ©es de la tÃ¢che prÃ©cÃ©dente.
       - N'oubliez pas d'activer `provide_context=True` pour accÃ©der aux XComs.
       - Les opÃ©rateurs de dÃ©pendance `>>` ou `<<` dÃ©finissent l'ordre d'exÃ©cution.

??? example "Code initial"
    ```python { .py .copy }
    def transformation_ventes(ventes, pays):
        """
        Transforme les donnÃ©es de vente en convertissant les prix en GBP.
        """
        ventes_transformees = []
        for vente in ventes:
            vente_transformee = vente.copy()     
            # SÃ©lectionner le taux de conversion appropriÃ©
            taux = (TAUX_CONVERSION['EUR_TO_GBP'] 
                    if vente['devise_origine'] == 'EUR' 
                    else TAUX_CONVERSION['USD_TO_GBP'])
            # Convertir les prix en GBP
            vente_transformee['prix_unitaire_gbp'] = round(vente['prix_unitaire_original'] * taux, 2)
            vente_transformee['prix_total_gbp'] = round(vente['prix_total_original'] * taux, 2)
            vente_transformee['taux_conversion'] = taux
            vente_transformee['date_transformation'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            ventes_transformees.append(vente_transformee)
        print(f"âœ“ Transformation des donnÃ©es de {pays} terminÃ©e")
        return ventes_transformees

    def transform_france(**context):
        """Transformation des donnÃ©es France"""
        pass

    transform_france_task = PythonOperator(
    # Ã€ complÃ©ter
    )
    ```

1. Ajoutez le code de transformation dans le fichier `etl_ventes_dag.py`.

2. ComplÃ©tez la fonction `transform_france` en utilisant XCom :
   
   [Doc xcoms](https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/xcoms.html)
   
   ```python
   ventes_france = context['ti'].xcom_pull(task_ids='........')
   return transformation_ventes(ventes_france, "France")
   ```


3. ComplÃ©tez la tÃ¢che `transform_france_task` avec :
   
      - `task_id='transform_france'`
      - `python_callable=transform_france`
      - `provide_context=True`
      - `dag=dag`

4. DÃ©finissez le flux de donnÃ©es entre les tÃ¢ches.

5. ğŸ” VÃ©rification :
   
   VÃ©rifiez les donnÃ©es transformÃ©es dans l'onglet XCom de la tÃ¢che `transform_france`.

??? success "Solution complÃ¨te"
    ```python { .py .copy }
    def transformation_ventes(ventes, pays):
    """
    Transforme les donnÃ©es de vente en convertissant les prix en GBP.
    """
    ventes_transformees = []
    for vente in ventes:
        vente_transformee = vente.copy()     
        # SÃ©lectionner le taux de conversion appropriÃ©
        taux = (TAUX_CONVERSION['EUR_TO_GBP'] 
                if vente['devise_origine'] == 'EUR' 
                else TAUX_CONVERSION['USD_TO_GBP'])
        # Convertir les prix en GBP
        vente_transformee['prix_unitaire_gbp'] = round(vente['prix_unitaire_original'] * taux, 2)
        vente_transformee['prix_total_gbp'] = round(vente['prix_total_original'] * taux, 2)
        vente_transformee['taux_conversion'] = taux
        vente_transformee['date_transformation'] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        ventes_transformees.append(vente_transformee)
    print(f"âœ“ Transformation des donnÃ©es de {pays} terminÃ©e")
    return ventes_transformees

    def transform_france(**context):
        """Transformation des donnÃ©es France"""
        ventes_france = context['task_instance'].xcom_pull(task_ids='extract_france')
        return transformation_ventes(ventes_france, "France")

    transform_france_task = PythonOperator(
        task_id='transform_france',
        python_callable=transform_france,
        provide_context=True,
        dag=dag,
    )
    ```

---

### Exercice 2 : Mise en place du pipeline pour les USA

#### Partie 1 : Extraction des donnÃ©es pour les USA

??? tip "Astuce"
       - Suivez la mÃªme structure que pour la France.
       - Utilisez une fonction `extract_usa` pour simuler l'extraction des donnÃ©es.

 
1. DÃ©finissez la tÃ¢che `extract_usa_task`  et la  fonction  `extract_usa` avec :
   
      - `task_id='extract_usa'`
      - `python_callable=extract_usa`
      - `dag=dag`

2. ğŸ” VÃ©rification :
   
   VÃ©rifiez les donnÃ©es extraites dans l'onglet XCom de la tÃ¢che `extract_usa`.

??? success "Solution complÃ¨te"
    ```python { .py .copy }
    def extract_usa():
    """Extraction des donnÃ©es USA"""
        return extraction_ventes("usa")
    # TÃ¢ches d'extraction
    extract_usa_task = PythonOperator(
        task_id='extract_usa',
        python_callable=extract_usa,
        dag=dag,
    )
    ```

---

#### Partie 2 : Transformation des donnÃ©es pour les USA

??? tip "Astuce"
    - Utilisez la mÃªme logique que pour la France.
    - Assurez-vous de bien rÃ©cupÃ©rer les donnÃ©es via `xcom_pull`.

 
1. Ajoutez la tÃ¢che `transform_usa_task` avec :
   
      - `task_id='transform_usa'`
      - `python_callable=transform_usa`
      - `provide_context=True`
      - `dag=dag`

2. DÃ©finissez le flux de donnÃ©es entre les tÃ¢ches.

3. ğŸ” VÃ©rification :
   
   VÃ©rifiez les donnÃ©es transformÃ©es dans l'onglet XCom de la tÃ¢che `transform_usa`.

??? success "Solution complÃ¨te"
    ```python { .py .copy }
    def transform_usa(**context):
        """Transformation des donnÃ©es USA"""
        ventes_usa = context['ti'].xcom_pull(task_ids='extract_usa')
        return {"region": "USA", "total_ventes": sum(ventes_usa["ventes"])}

    transform_usa_task = PythonOperator(
        task_id='transform_usa',
        python_callable=transform_usa,
        provide_context=True,
        dag=dag,
    )
    # DÃ©finition du flux
    extract_usa_task >> transform_usa_task
    ```

---

### Exercice 3 : Chargement des donnÃ©es dans un CSV

??? tip "Astuce"
    - Utilisez `pandas` pour crÃ©er un DataFrame et sauvegarder les donnÃ©es dans un fichier CSV.
    - Assurez-vous que le rÃ©pertoire de sortie existe.

??? example "Code initial"
    ```python { .py .copy }
    def load_data(**context):
        """Chargement des donnÃ©es transformÃ©es"""
        try:
            # RÃ©cupÃ©rer les donnÃ©es transformÃ©es
            ventes_usa = context['......'].xcom_pull(task_ids='......')
            ventes_france = context['......'].xcom_pull(task_ids='......')
            
            # Combiner les donnÃ©es
            toutes_ventes = ventes_usa + ventes_france
            
            # CrÃ©er le DataFrame
            df = pd.DataFrame(toutes_ventes)
            
            # GÃ©rer le fichier existant
            if os.path.exists(CSV_FILE):
                df_existant = pd.read_csv(CSV_FILE)
                df = pd.concat([df_existant, df], ignore_index=True)
            
            # Sauvegarder
            df.to_csv(CSV_FILE, index=False)
            print(f"âœ“ DonnÃ©es chargÃ©es dans {CSV_FILE}")
            print(f"âœ“ Nombre total d'enregistrements: {len(df)}")
            
        except Exception as e:
            print(f"âŒ Erreur lors du chargement: {str(e)}")
            raise

    # TÃ¢che de chargement
    load_task = PythonOperator(
         # Ã€ complÃ©ter
    )

    # DÃ©finition du flux de donnÃ©es
    # Ã€ complÃ©ter
    ```

1. ComplÃ©tez la fonction `load_data` en utilisant XCom
2. Ajoutez la tÃ¢che `load_data_task` avec :
   
      - `task_id='load_data'`
      - `python_callable=load_data`
      - `provide_context=True`
      - `dag=dag`

3. DÃ©finissez le flux de donnÃ©es entre les tÃ¢ches.

4. ğŸ” VÃ©rification :
   
   VÃ©rifiez que le fichier `data/ventes_transformed.csv` est crÃ©Ã© avec les donnÃ©es correctes.

??? success "Solution complÃ¨te"
    ```python { .py .copy }
    def load_data(**context):
        """Chargement des donnÃ©es transformÃ©es"""
        try:
            # RÃ©cupÃ©rer les donnÃ©es transformÃ©es
            ventes_usa = context['task_instance'].xcom_pull(task_ids='transform_usa')
            ventes_france = context['task_instance'].xcom_pull(task_ids='transform_france')
            
            # Combiner les donnÃ©es
            toutes_ventes = ventes_usa + ventes_france
            
            # CrÃ©er le DataFrame
            df = pd.DataFrame(toutes_ventes)
            
            # GÃ©rer le fichier existant
            if os.path.exists(CSV_FILE):
                df_existant = pd.read_csv(CSV_FILE)
                df = pd.concat([df_existant, df], ignore_index=True)
            
            # Sauvegarder
            df.to_csv(CSV_FILE, index=False)
            print(f"âœ“ DonnÃ©es chargÃ©es dans {CSV_FILE}")
            print(f"âœ“ Nombre total d'enregistrements: {len(df)}")
            
        except Exception as e:
            print(f"âŒ Erreur lors du chargement: {str(e)}")
            raise
    # TÃ¢che de chargement
    load_task = PythonOperator(
        task_id='load_data',
        python_callable=load_data,
        provide_context=True,
        dag=dag,
    )
    # DÃ©finition du flux de donnÃ©es
    extract_usa_task >> transform_usa_task >> load_task
    extract_france_task >> transform_france_task >> load_task
    ```

---

### Exercice 4 : CrÃ©ation du rapport

??? tip "Astuce"
    - Utilisez `pandas` pour gÃ©nÃ©rer un rapport consolidÃ©.
    - Ajoutez des calculs supplÃ©mentaires comme la moyenne ou le total des ventes.

??? example "Code initial"
    ```python { .py .copy }
    def generate_report(**context):
        """GÃ©nÃ¨re un rapport consolidÃ©."""
        df = pd.read_csv('output/ventes.csv')
        total_ventes = df['total_ventes'].sum()
        moyenne_ventes = df['total_ventes'].mean()
        rapport = f"Total des ventes : {total_ventes}\nMoyenne des ventes : {moyenne_ventes}"
        return rapport
    ```

1. Ajoutez la tÃ¢che `generate_report_task` avec :
   
      - `task_id='generate_report'`
      - `python_callable=generate_report`
      - `provide_context=True`
      - `dag=dag`

2. DÃ©finissez le flux de donnÃ©es entre les tÃ¢ches.

3. ğŸ” VÃ©rification :
   
   VÃ©rifiez que le rapport est gÃ©nÃ©rÃ© correctement.

??? success "Solution complÃ¨te"
    ```python
    def generate_report(**context):
        """GÃ©nÃ¨re un rapport consolidÃ©."""
        df = pd.read_csv('output/ventes.csv')
        total_ventes = df['total_ventes'].sum()
        moyenne_ventes = df['total_ventes'].mean()
        rapport = f"Total des ventes : {total_ventes}\nMoyenne des ventes : {moyenne_ventes}"
        return rapport

    generate_report_task = PythonOperator(
        task_id='generate_report',
        python_callable=generate_report,
        provide_context=True,
        dag=dag,
    )

    # DÃ©finition du flux
    load_data_task >> generate_report_task
    ```

---

## ğŸ‰ RÃ©sultat final

Vous avez maintenant un pipeline ETL complet avec Airflow qui :

1. Extrait les donnÃ©es de ventes pour la France et les USA.
   
2. Transforme les donnÃ©es en calculant le total des ventes.
   
3. Charge les donnÃ©es transformÃ©es dans un fichier CSV.

4. GÃ©nÃ¨re un rapport consolidÃ©.